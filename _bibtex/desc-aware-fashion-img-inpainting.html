@inproceedings{10.1145/3397125.3397155,
author = {K\i{}nl\i{}, Furkan and \"{O}zcan, Bar\i{}\c{s} and K\i{}ra\c{c}, Furkan},
title = {Description-Aware Fashion Image Inpainting with Convolutional Neural Networks in Coarse-to-Fine Manner},
year = {2020},
isbn = {9781450377492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397125.3397155},
doi = {10.1145/3397125.3397155},
abstract = {Inpainting a particular missing region in an image is a challenging vision task, and promising improvements on this task have been achieved with the help of the recent developments in vision-related deep learning studies. Although it may have a direct impact on the decisions of AI-based fashion analysis systems, a limited number of studies for image inpainting have been done in fashion domain, so far. In this study, we propose a multi-modal generative deep learning approach for filling the missing parts in fashion images by constraining visual features with textual features extracted from image descriptions. Our model is composed of four main blocks which can be introduced as textual feature extractor, coarse image generator guided by textual features, fine image generator enhancing the coarse output, and lastly global and local discriminators improving refined outputs. Several experiments conducted on FashionGen dataset with different combination of neural network components show that our multi-modal approach is able to generate visually plausible patches to fill the missing parts in the images.},
booktitle = {Proceedings of the 2020 6th International Conference on Computer and Technology Applications},
pages = {74â€“79},
numpages = {6},
keywords = {image reconstruction, multi-modal neural networks, image inpainting, generative learning, fashion analysis, deep learning},
location = {Antalya, Turkey},
series = {ICCTA '20}
}